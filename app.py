import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score, classification_report, roc_curve
import warnings

warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Predicci√≥n de Rendimiento Acad√©mico - IST Azuay",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos personalizados
st.markdown("""
    <style>
    .main-header {
        text-align: center;
        color: #1f77b4;
        font-size: 2.5em;
        font-weight: bold;
        margin-bottom: 10px;
    }
    .sub-header {
        text-align: center;
        color: #555;
        font-size: 1.1em;
        margin-bottom: 30px;
    }
    </style>
""", unsafe_allow_html=True)

# T√≠tulo principal
st.markdown('<div class="main-header">üìö Predicci√≥n de Rendimiento Acad√©mico</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">Instituto Superior Tecnol√≥gico del Azuay</div>', unsafe_allow_html=True)

# Barra lateral de navegaci√≥n
st.sidebar.title("üîç Navegaci√≥n")
page = st.sidebar.radio(
    "Selecciona una secci√≥n:",
    ["üìä Inicio", "üìà An√°lisis Exploratorio", "ü§ñ Comparaci√≥n de Modelos", "üéØ Predictor en Tiempo Real"]
)

# Cargar datos
@st.cache_data
def load_data():
    """Cargar el dataset consolidado."""
    df = pd.read_csv("academic_performance_master.csv")
    df['Exito_Academico'] = df['Estado_Asignatura'].apply(lambda x: 1 if x == 'APROBADO' else 0)
    return df

@st.cache_data
def prepare_data(df):
    """Preparar datos para el modelado."""
    df_model = df.copy()
    df_model = pd.get_dummies(df_model, columns=['Tipo_Ingreso', 'Carrera', 'Periodo'], drop_first=True)
    model_features = [col for col in df_model.columns if col.startswith(('Asistencia', 'Num_matricula', 'Tipo_Ingreso_', 'Carrera_', 'Periodo_'))]
    df_final = df_model[model_features + ['Exito_Academico']].dropna()
    return df_final, model_features

@st.cache_resource
def train_models(X_train, y_train):
    """Entrenar los modelos."""
    models = {
        "Logistic Regression": LogisticRegression(max_iter=1000, solver='liblinear', random_state=42),
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
        "XGBoost": XGBClassifier(eval_metric='logloss', random_state=42, n_jobs=-1, verbose=0)
    }
    
    trained_models = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        trained_models[name] = model
    
    return trained_models

# Cargar datos
df = load_data()
df_final, model_features = prepare_data(df)

# Divisi√≥n de datos
X = df_final[model_features]
y = df_final['Exito_Academico']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Entrenar modelos
trained_models = train_models(X_train, y_train)

# P√°gina: Inicio
if page == "üìä Inicio":
    st.header("Bienvenido al Sistema de Predicci√≥n de Rendimiento Acad√©mico")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total de Registros", len(df), "Periodos Acad√©micos: 7")
    
    with col2:
        tasa_exito = (df['Exito_Academico'].sum() / len(df)) * 100
        st.metric("Tasa de √âxito Promedio", f"{tasa_exito:.1f}%", "Estudiantes Aprobados")
    
    with col3:
        num_carreras = df['Carrera'].nunique()
        st.metric("Carreras Registradas", num_carreras, "Programas Acad√©micos")
    
    st.markdown("---")
    
    st.subheader("üìã Descripci√≥n del Proyecto")
    st.write("""
    Este sistema utiliza **modelos de aprendizaje autom√°tico** para predecir el rendimiento acad√©mico 
    de los estudiantes del Instituto Superior Tecnol√≥gico del Azuay. El objetivo es identificar 
    tempranamente a los estudiantes en riesgo de no aprobar sus asignaturas, permitiendo implementar 
    estrategias de intervenci√≥n y apoyo acad√©mico.
    
    **Caracter√≠sticas principales:**
    - üìä An√°lisis exploratorio de datos con visualizaciones interactivas
    - ü§ñ Comparaci√≥n de tres modelos predictivos (Regresi√≥n Log√≠stica, Random Forest, XGBoost)
    - üéØ Predictor en tiempo real para estudiantes individuales
    - üìà M√©tricas de rendimiento detalladas
    """)
    
    st.markdown("---")
    
    st.subheader("üöÄ C√≥mo Usar Esta Aplicaci√≥n")
    st.write("""
    1. **üìà An√°lisis Exploratorio:** Explora los datos hist√≥ricos y visualiza tendencias.
    2. **ü§ñ Comparaci√≥n de Modelos:** Compara el rendimiento de diferentes algoritmos.
    3. **üéØ Predictor:** Realiza predicciones para estudiantes individuales.
    """)

# P√°gina: An√°lisis Exploratorio
elif page == "üìà An√°lisis Exploratorio":
    st.header("üìà An√°lisis Exploratorio de Datos (EDA)")
    
    # Tabs para diferentes an√°lisis
    tab1, tab2, tab3, tab4 = st.tabs(["Distribuci√≥n de Notas", "√âxito por Periodo", "√âxito por Carrera", "Asistencia vs Nota"])
    
    with tab1:
        st.subheader("Distribuci√≥n de la Nota Final")
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(df['Nota_final'], bins=20, kde=True, ax=ax)
        ax.set_title('Distribuci√≥n de la Nota Final')
        ax.set_xlabel('Nota Final')
        ax.set_ylabel('Frecuencia')
        st.pyplot(fig)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Nota Promedio", f"{df['Nota_final'].mean():.2f}")
        with col2:
            st.metric("Nota M√≠nima", f"{df['Nota_final'].min():.2f}")
        with col3:
            st.metric("Nota M√°xima", f"{df['Nota_final'].max():.2f}")
    
    with tab2:
        st.subheader("Tasa de √âxito Acad√©mico por Periodo")
        period_success = df.groupby('Periodo')['Exito_Academico'].agg(['mean', 'count']).reset_index()
        period_success.columns = ['Periodo', 'Tasa_Exito', 'Total_Registros']
        
        fig, ax = plt.subplots(figsize=(12, 6))
        sns.barplot(x='Periodo', y='Tasa_Exito', data=period_success, ax=ax)
        ax.set_title('Tasa de √âxito Acad√©mico por Periodo')
        ax.set_xlabel('Periodo Acad√©mico')
        ax.set_ylabel('Tasa de √âxito')
        ax.set_ylim([0, 1])
        plt.xticks(rotation=45)
        st.pyplot(fig)
        
        st.dataframe(period_success, use_container_width=True)
    
    with tab3:
        st.subheader("Tasa de √âxito por Carrera (Top 10)")
        career_success = df.groupby('Carrera')['Exito_Academico'].agg(['mean', 'count']).reset_index()
        career_success = career_success[career_success['count'] > 100].sort_values(by='mean', ascending=False).head(10)
        career_success.columns = ['Carrera', 'Tasa_Exito', 'Total_Registros']
        
        fig, ax = plt.subplots(figsize=(12, 8))
        sns.barplot(x='Tasa_Exito', y='Carrera', data=career_success, ax=ax)
        ax.set_title('Top 10 Carreras por Tasa de √âxito')
        ax.set_xlabel('Tasa de √âxito')
        st.pyplot(fig)
        
        st.dataframe(career_success, use_container_width=True)
    
    with tab4:
        st.subheader("Relaci√≥n entre Asistencia y Nota Final")
        # Muestra para mejor visualizaci√≥n
        sample_df = df.sample(n=min(5000, len(df)), random_state=42)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.scatter(sample_df['Asistencia'], sample_df['Nota_final'], alpha=0.5)
        ax.set_title('Relaci√≥n entre Asistencia y Nota Final (Muestra)')
        ax.set_xlabel('Asistencia (%)')
        ax.set_ylabel('Nota Final')
        st.pyplot(fig)
        
        # Correlaci√≥n
        corr = df['Asistencia'].corr(df['Nota_final'])
        st.info(f"**Correlaci√≥n de Pearson:** {corr:.4f} (Relaci√≥n positiva fuerte)")

# P√°gina: Comparaci√≥n de Modelos
elif page == "ü§ñ Comparaci√≥n de Modelos":
    st.header("ü§ñ Comparaci√≥n de Modelos Predictivos")
    
    # Evaluar modelos
    results = {}
    for name, model in trained_models.items():
        y_proba = model.predict_proba(X_test)[:, 1]
        y_pred = model.predict(X_test)
        auc_score = roc_auc_score(y_test, y_proba)
        report = classification_report(y_test, y_pred, output_dict=True)
        results[name] = {
            "AUC": auc_score,
            "Accuracy": report['accuracy'],
            "Precision": report['1']['precision'],
            "Recall": report['1']['recall'],
            "F1": report['1']['f1-score'],
            "y_proba": y_proba
        }
    
    # Tabla de comparaci√≥n
    st.subheader("üìä Tabla de Comparaci√≥n de Modelos")
    comparison_df = pd.DataFrame({
        "Modelo": list(results.keys()),
        "AUC-ROC": [results[m]["AUC"] for m in results.keys()],
        "Accuracy": [results[m]["Accuracy"] for m in results.keys()],
        "Precisi√≥n": [results[m]["Precision"] for m in results.keys()],
        "Recall": [results[m]["Recall"] for m in results.keys()],
        "F1-Score": [results[m]["F1"] for m in results.keys()]
    })
    
    #st.dataframe(comparison_df.style.format("{:.4f}"), use_container_width=True)
    numeric_cols = comparison_df.select_dtypes(include=["float", "int"]).columns
    format_dict = {col: "{:.4f}" for col in numeric_cols}

    st.dataframe(
        comparison_df.style.format(format_dict),
        use_container_width=True
    )
    
    # Gr√°fico de comparaci√≥n de AUC
    st.subheader("üìà Comparaci√≥n de AUC-ROC")
    fig, ax = plt.subplots(figsize=(10, 6))
    models_list = list(results.keys())
    auc_scores = [results[m]["AUC"] for m in models_list]
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
    bars = ax.bar(models_list, auc_scores, color=colors)
    ax.set_ylabel('AUC-ROC Score')
    ax.set_title('Comparaci√≥n de AUC-ROC entre Modelos')
    ax.set_ylim([0.8, 1.0])
    
    # A√±adir valores en las barras
    for bar, score in zip(bars, auc_scores):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{score:.4f}', ha='center', va='bottom')
    
    st.pyplot(fig)
    
    # Curvas ROC
    st.subheader("üìâ Curvas ROC")
    fig, ax = plt.subplots(figsize=(10, 8))
    
    for name, model in trained_models.items():
        y_proba = results[name]["y_proba"]
        fpr, tpr, _ = roc_curve(y_test, y_proba)
        auc = results[name]["AUC"]
        ax.plot(fpr, tpr, label=f'{name} (AUC = {auc:.4f})')
    
    ax.plot([0, 1], [0, 1], 'k--', label='Clasificador Aleatorio')
    ax.set_xlabel('Tasa de Falsos Positivos')
    ax.set_ylabel('Tasa de Verdaderos Positivos')
    ax.set_title('Curvas ROC - Comparaci√≥n de Modelos')
    ax.legend(loc='lower right')
    st.pyplot(fig)
    
    # Selecci√≥n del mejor modelo
    st.markdown("---")
    best_model_name = max(results, key=lambda x: results[x]["AUC"])
    st.success(f"‚úÖ **Mejor Modelo Seleccionado:** {best_model_name} (AUC: {results[best_model_name]['AUC']:.4f})")

# P√°gina: Predictor en Tiempo Real
elif page == "üéØ Predictor en Tiempo Real":
    st.header("üéØ Predictor de Rendimiento Acad√©mico")
    
    st.write("Ingresa los datos del estudiante para realizar una predicci√≥n de √©xito acad√©mico.")
    
    # Usar el mejor modelo (XGBoost)
    best_model = trained_models["XGBoost"]
    
    # Inputs del usuario
    col1, col2 = st.columns(2)
    
    with col1:
        asistencia = st.slider("Asistencia (%)", 0, 100, 80)
        num_matricula = st.number_input("N√∫mero de Matr√≠cula", 0, 10, 1)
    
    with col2:
        tipo_ingreso = st.selectbox("Tipo de Ingreso", df['Tipo_Ingreso'].unique())
        carrera = st.selectbox("Carrera", df['Carrera'].unique())
    
    periodo = st.selectbox("Periodo Acad√©mico", df['Periodo'].unique())
    
    # Preparar datos para predicci√≥n
    if st.button("üîÆ Realizar Predicci√≥n", use_container_width=True):
        # Crear un DataFrame con los datos del estudiante
        input_data = pd.DataFrame({
            'Asistencia': [asistencia],
            'Num_matricula': [num_matricula],
            'Tipo_Ingreso': [tipo_ingreso],
            'Carrera': [carrera],
            'Periodo': [periodo]
        })
        
        # Codificar variables categ√≥ricas
        input_data = pd.get_dummies(input_data, columns=['Tipo_Ingreso', 'Carrera', 'Periodo'], drop_first=True)
        
        # Alinear con las caracter√≠sticas del modelo
        for col in model_features:
            if col not in input_data.columns:
                input_data[col] = 0
        
        input_data = input_data[model_features]
        
        # Realizar predicci√≥n
        prediction_proba = best_model.predict_proba(input_data)[0]
        prediction = best_model.predict(input_data)[0]
        
        # Mostrar resultados
        st.markdown("---")
        st.subheader("üìä Resultado de la Predicci√≥n")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if prediction == 1:
                st.success("‚úÖ **Predicci√≥n: APROBADO**")
            else:
                st.error("‚ùå **Predicci√≥n: NO APROBADO**")
        
        with col2:
            st.metric("Probabilidad de Aprobaci√≥n", f"{prediction_proba[1]*100:.1f}%")
        
        with col3:
            st.metric("Probabilidad de No Aprobaci√≥n", f"{prediction_proba[0]*100:.1f}%")
        
        # Gr√°fico de probabilidades
        fig, ax = plt.subplots(figsize=(8, 5))
        categories = ['No Aprobado', 'Aprobado']
        probabilities = prediction_proba
        colors = ['#d62728', '#2ca02c']
        bars = ax.bar(categories, probabilities, color=colors)
        ax.set_ylabel('Probabilidad')
        ax.set_title('Distribuci√≥n de Probabilidades')
        ax.set_ylim([0, 1])
        
        for bar, prob in zip(bars, probabilities):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                    f'{prob*100:.1f}%', ha='center', va='bottom')
        
        st.pyplot(fig)
        
        # Recomendaciones
        st.markdown("---")
        st.subheader("üí° Recomendaciones")
        
        if prediction == 1:
            st.info("""
            ‚úÖ El estudiante tiene una alta probabilidad de aprobar la asignatura.
            - Mantener el nivel de asistencia actual.
            - Continuar con las estrategias de estudio que han sido efectivas.
            """)
        else:
            st.warning("""
            ‚ö†Ô∏è El estudiante est√° en riesgo de no aprobar la asignatura.
            - **Aumentar la asistencia:** La asistencia es el predictor m√°s importante.
            - **Solicitar tutor√≠as:** Buscar apoyo acad√©mico adicional.
            - **Revisar m√©todos de estudio:** Considerar cambios en las estrategias de aprendizaje.
            - **Comunicarse con el docente:** Informar sobre dificultades y buscar orientaci√≥n.
            """)

# Footer
st.markdown("---")
st.markdown("""
    <div style='text-align: center; color: #888; font-size: 0.9em;'>
    <p>Sistema de Predicci√≥n de Rendimiento Acad√©mico - Instituto Superior Tecnol√≥gico del Azuay</p>
    <p>Desarrollado con Python, Scikit-learn, XGBoost y Streamlit</p>
    </div>
""", unsafe_allow_html=True)
